{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtFYdSldbXia+cdPhlKu8h"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "DZ_f3gcDONP0",
        "outputId": "1977e85b-4029-4ee4-f224-bcfabd5c8e84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x79750818b130>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://90f61b8bf10a:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"challenge.csv\")"
      ],
      "metadata": {
        "id": "nmuRBRVeOfJN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIt8rj1OOwFl",
        "outputId": "76f32fff-f699-42fc-8787-73e374cb4b19"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------+-----------------+----------+\n",
            "|     ip_address|       Country|      Domain Name|Bytes_used|\n",
            "+---------------+--------------+-----------------+----------+\n",
            "|  52.81.192.172|         China| odnoklassniki.ru|       463|\n",
            "| 119.239.207.13|         China|         youtu.be|        51|\n",
            "|  68.69.217.210|         China|        adobe.com|        10|\n",
            "|   7.191.21.223|      Bulgaria|     linkedin.com|       853|\n",
            "|   211.13.10.68|     Indonesia|          hud.gov|        29|\n",
            "|   239.80.21.97|      Suriname|       smh.com.au|       218|\n",
            "|106.214.106.233|       Jamaica|    amazonaws.com|        95|\n",
            "| 127.242.24.138|         China| surveymonkey.com|       123|\n",
            "|     99.2.6.139|Czech Republic|     geocities.jp|       322|\n",
            "|   237.54.11.63|         China|       amazon.com|        83|\n",
            "| 252.141.157.25|         Japan|      cornell.edu|       374|\n",
            "|185.220.128.248|       Belgium|       weebly.com|       389|\n",
            "|   151.77.19.45|   Afghanistan|independent.co.uk|       282|\n",
            "|  9.161.158.225|     Indonesia|    bloglines.com|       726|\n",
            "| 156.144.61.155|Czech Republic|   slideshare.net|       657|\n",
            "|   8.96.188.151|     Indonesia|          ibm.com|       517|\n",
            "|      5.72.7.65|        Mexico|         youtu.be|       877|\n",
            "|227.110.112.144|       Croatia|         ehow.com|       287|\n",
            "|    81.71.28.97|      Thailand|          last.fm|       588|\n",
            "|  9.255.129.184|      Thailand|          mtv.com|       114|\n",
            "+---------------+--------------+-----------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import *\n",
        "spark_df = spark_df.withColumn(\"Is_Mexico\", when(spark_df.Country == \"Mexico\", 'YES').otherwise(\"NO\"))"
      ],
      "metadata": {
        "id": "yXhG2bzxOz0E"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spark_df.show()\n",
        "#spark_df = spark_df.withColumn('Bytes_used', spark_df.Bytes_used.cast('float'))\n",
        "spark_df = spark_df.withColumn(\"Bytes_used\", spark_df.Bytes_used.cast('float'))\n",
        "#spark_df.printSchema()"
      ],
      "metadata": {
        "id": "xKDRP14YPNAM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as sqlfunc\n",
        "new_df = spark_df.groupBy(\"Is_Mexico\").agg(sqlfunc.sum('Bytes_used'))\n",
        "new_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7PPjR9HPMI4",
        "outputId": "e0981613-3d9f-4dcb-8d9b-83abb3d0af6b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------------+\n",
            "|Is_Mexico|sum(Bytes_used)|\n",
            "+---------+---------------+\n",
            "|      YES|         6293.0|\n",
            "|       NO|       508076.0|\n",
            "+---------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = spark_df.groupBy(\"Country\").agg(sqlfunc.countDistinct(spark_df.ip_address).alias(\"no_of_ips\"))"
      ],
      "metadata": {
        "id": "knzyiHs3Oum1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df.sort(col('no_of_ips').desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rpkiytqSsK-",
        "outputId": "2113fc61-90b7-49a7-efa9-cc819caa55f6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+---------+\n",
            "|       Country|no_of_ips|\n",
            "+--------------+---------+\n",
            "|         China|      172|\n",
            "|     Indonesia|      114|\n",
            "|   Philippines|       65|\n",
            "|        Russia|       56|\n",
            "|        Brazil|       35|\n",
            "|        Poland|       31|\n",
            "|        Sweden|       28|\n",
            "|         Japan|       25|\n",
            "|Czech Republic|       23|\n",
            "|      Portugal|       23|\n",
            "|        France|       21|\n",
            "|          Peru|       19|\n",
            "|      Colombia|       17|\n",
            "| United States|       15|\n",
            "|       Ukraine|       14|\n",
            "|     Argentina|       14|\n",
            "|        Mexico|       13|\n",
            "|      Thailand|       12|\n",
            "|       Nigeria|       11|\n",
            "|        Canada|       11|\n",
            "+--------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}